{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from PIL import Image\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from DatasetGenerator import DatasetGenerator\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "from plots import plot_roc\n",
    "from DensenetModels import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 20\n",
    "nnClassCount = 14\n",
    "# root = f'checkpoints/{ratio}_nf'\n",
    "root = f'checkpoints/unsup_{ratio}'\n",
    "\n",
    "pathModel = f'{root}/min_loss.pth.tar'\n",
    "# pathModel = f'{root}/best_auroc.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/unsup_20/min_loss.pth.tar'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathModel\n",
    "# Test AUROC mean  0.8459400922002926\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 10510 with 14 class labels from file path database/xrays/new_split/test_list.txt \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_root = 'database/xrays'\n",
    "file_test = 'new_split/test_list.txt'\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "test_transformSequence = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.TenCrop(224),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "    transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])) \n",
    "])\n",
    "iniclude_nf = nnClassCount == 15\n",
    "datasetTest = DatasetGenerator(data_root, file_test, transform=test_transformSequence, iniclude_nf=iniclude_nf)\n",
    "dataLoaderTest = DataLoader(dataset=datasetTest, batch_size=32, num_workers=2, shuffle=False )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DenseNet121(nnClassCount, True).cuda()\n",
    "modelCheckpoint = torch.load(pathModel)\n",
    "model.load_state_dict(modelCheckpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 10/329 [00:06<03:24,  1.56it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def computeAUROC(dataGT, dataPRED):\n",
    "        \n",
    "    outAUROC = []\n",
    "    datanpGT = dataGT.cpu().numpy()\n",
    "    datanpPRED = dataPRED.cpu().numpy()\n",
    "    for i in range(nnClassCount):\n",
    "        outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "    return outAUROC\n",
    "\n",
    "#--------------------------------------------------------------------------------  \n",
    "\n",
    "# def test ():\n",
    "CLASS_NAMES = dataLoaderTest.dataset._class_labels\n",
    "\n",
    "cudnn.benchmark = True\n",
    "outGT = torch.FloatTensor().cuda()\n",
    "outPRED = torch.FloatTensor().cuda()\n",
    "model.eval()\n",
    "for i, (input, target) in tqdm(enumerate(dataLoaderTest), total=len(dataLoaderTest)):\n",
    "    with torch.no_grad():\n",
    "        target = target.cuda()\n",
    "        outGT = torch.cat((outGT, target), 0)\n",
    "        bs, n_crops, c, h, w = input.size()\n",
    "        varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda())\n",
    "        out = model(varInput)\n",
    "        outMean = out.view(bs, n_crops, -1).mean(1)\n",
    "        outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "aurocIndividual = computeAUROC(outGT, outPRED)\n",
    "\n",
    "# plot_roc(outGT, outPRED, CLASS_NAMES)\n",
    "aurocMean = np.array(aurocIndividual).mean()\n",
    "print ('Test AUROC mean ', aurocMean)\n",
    "\n",
    "f = open(f'{root}/test_auroc.txt', 'w')\n",
    "\n",
    "f.write(f\"Test AUROC mean:  {aurocMean:0.6f} \\n \")       \n",
    "for i in range (0, len(aurocIndividual)):\n",
    "    print (CLASS_NAMES[i], ' ', aurocIndividual[i])\n",
    "    f.write(f\"{CLASS_NAMES[i]}:  {aurocIndividual[i]:0.6f} \\n \")\n",
    "f.close()\n",
    "np.save(f\"{root}/test_auroc_mean.npy\", np.array([aurocMean]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = outPRED.argmax(dim=0).data.cpu().numpy()\n",
    "im_infos = np.array(datasetTest._imdb)[arg]\n",
    "heat_map_preds = outPRED[arg].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feats = model.densenet121.features\n",
    "model_feats.eval()\n",
    "#---- Initialize the weights\n",
    "weights = list(model_feats.parameters())[-2]\n",
    "transCrop = 224\n",
    "#---- Initialize the image transform - resize + normalize\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "transformList = []\n",
    "transformList.append(transforms.Resize(transCrop))\n",
    "transformList.append(transforms.ToTensor())\n",
    "transformList.append(normalize)\n",
    "transformSequence = transforms.Compose(transformList)\n",
    "\n",
    "for index, info in enumerate(im_infos):     \n",
    "    #---- Load image, transform, convert\n",
    "    imageData = Image.open(info['im_path']).convert('RGB')\n",
    "    imageData = transformSequence(imageData)\n",
    "    imageData = imageData.unsqueeze_(0)\n",
    "\n",
    "    input = torch.autograd.Variable(imageData)\n",
    "\n",
    "    model_feats.cuda()\n",
    "    output = model_feats(input.cuda())\n",
    "\n",
    "    #---- Generate heatmap\n",
    "    heatmap = None\n",
    "    for i in range (0, len(weights)):\n",
    "        map = output[0,i,:,:]\n",
    "        if i == 0: heatmap = weights[i] * map\n",
    "        else: heatmap += weights[i] * map\n",
    "\n",
    "    #---- Blend original and heatmap \n",
    "    npHeatmap = heatmap.cpu().data.numpy()\n",
    "\n",
    "    imgOriginal = cv2.imread(info['im_path'], 1)\n",
    "    imgOriginal = cv2.resize(imgOriginal, (transCrop, transCrop))\n",
    "\n",
    "    cam = npHeatmap / np.max(npHeatmap)\n",
    "    cam = cv2.resize(cam, (transCrop, transCrop))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
    "\n",
    "    img = heatmap * 0.5 + imgOriginal\n",
    "\n",
    "    cv2.imwrite(f'{root}/{index}_heatmap.png', img)\n",
    "    cv2.imwrite(f'{root}/{index}_org.png', imgOriginal)\n",
    "    f = open(f'{root}/{index}.txt', 'w')\n",
    "    for index, value in enumerate(heat_map_preds[index]):\n",
    "        f.write(f\"{CLASS_NAMES[index]}:  {value:0.3f}           {'gt' if index in info['labels'] else ''} \\n\")\n",
    "    \n",
    "    f.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#8a2244', '#da8c22', '#c687d5', '#80d6f8', '#440f06', '#000075', '#000000', '#e6194B', '#f58231', '#ffe119', '#bfef45',\n",
    "'#02a92c', '#3a3075', '#3dde43', '#baa980', '#170eb8', '#f032e6', '#a9a9a9', '#fabebe', '#ffd8b1', '#fffac8', '#aaffc3', '#5b7cd4',\n",
    "'#3e319d', '#a837b2', '#400dd2', '#f8d307']\n",
    "gt = outGT.data.cpu().numpy()\n",
    "preds = outPRED.data.cpu().numpy()\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    fpr, tpr, _ = metrics.roc_curve(gt[:, i], preds[:, i])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, colors[i], label = f'{CLASS_NAMES[i]} AUC = {roc_auc:0.2f}')\n",
    "\n",
    "plt.legend(loc = 'lower right', )\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "fig.savefig(f'{root}/roc_curve.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_01 = (preds > 0.1).astype(int)\n",
    "cmat=metrics.multilabel_confusion_matrix(gt, pred_01, labels=None)\n",
    "cmat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training validation loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.title('Validation Loss')\n",
    "v_loss = np.load(f\"{root}/val_loss_epoch.npy\")\n",
    "plt.plot(v_loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "fig.savefig(f'{root}/val_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_uda_loss = np.load(f\"{root}/train_uda_loss.npy\")\n",
    "train_loss = np.load(f\"{root}/train_loss.npy\")\n",
    "loss = train_uda_loss + train_loss\n",
    "mean_loss = np.zeros((100))\n",
    "iter_per_epoch = len(loss)//100\n",
    "\n",
    "for i in range(100):\n",
    "    mean_loss[i] = loss[i*iter_per_epoch: (i+1)*iter_per_epoch].mean()\n",
    "    \n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.title('Training Loss')\n",
    "plt.plot(mean_loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "fig.savefig(f'{root}/train_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uda loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.load(f\"{root}/train_uda_loss.npy\")\n",
    "# train_loss = np.load(f\"{root}/train_loss.npy\")\n",
    "# loss = train_uda_loss + train_loss\n",
    "mean_loss = np.zeros((100))\n",
    "iter_per_epoch = len(loss)//100\n",
    "\n",
    "for i in range(100):\n",
    "    mean_loss[i] = loss[i*iter_per_epoch: (i+1)*iter_per_epoch].mean()\n",
    "    \n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.title('KL Divergence')\n",
    "plt.plot(mean_loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "fig.savefig(f'{root}/train_uda_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sup 2 Test best AUROC mean  0.6902797700931337\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xrays]",
   "language": "python",
   "name": "conda-env-xrays-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
